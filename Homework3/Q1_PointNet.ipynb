{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 2048, 3)\n",
      "(2048, 1)\n"
     ]
    }
   ],
   "source": [
    "# load training data and labels\n",
    "data0 = utils.load_h5(\"ply_data_train0.h5\")\n",
    "data1 = utils.load_h5(\"ply_data_train1.h5\")\n",
    "data2 = utils.load_h5(\"ply_data_train2.h5\")\n",
    "data3 = utils.load_h5(\"ply_data_train3.h5\")\n",
    "data4 = utils.load_h5(\"ply_data_train4.h5\")\n",
    "\n",
    "train_data = data0[0]\n",
    "print(np.shape(train_data))\n",
    "\n",
    "train_labels = data0[1]\n",
    "catagory_names = utils.get_category_names()\n",
    "print(np.shape(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9840, 2048, 3)\n",
      "(9840, 1)\n"
     ]
    }
   ],
   "source": [
    "# aggregate training data, training label\n",
    "# train_data = np.append(data0[0], data1[0], axis=0)\n",
    "# train_data = np.append(train_data, data2[0], axis=0)\n",
    "# train_data = np.append(train_data, data3[0], axis=0)\n",
    "# train_data = np.append(train_data, data4[0], axis=0)\n",
    "# print(np.shape(train_data))\n",
    "\n",
    "# train_labels = np.append(data0[1], data1[1], axis=0)\n",
    "# train_labels = np.append(train_labels, data2[1], axis=0)\n",
    "# train_labels = np.append(train_labels, data3[1], axis=0)\n",
    "# train_labels = np.append(train_labels, data4[1], axis=0)\n",
    "# print(np.shape(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(420, 2048, 3)\n"
     ]
    }
   ],
   "source": [
    "# load test data\n",
    "test0 = utils.load_h5(\"ply_data_test0.h5\")\n",
    "test1 = utils.load_h5(\"ply_data_test1.h5\")\n",
    "# print(np.shape(test1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2468, 2048, 3)\n",
      "(2468, 1)\n"
     ]
    }
   ],
   "source": [
    "# aggregate test data, test label\n",
    "test_data = np.append(test0[0], test1[0], axis=0)\n",
    "test_labels = np.append(test0[1], test1[1], axis=0)\n",
    "print(np.shape(test_data))\n",
    "print(np.shape(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 40)\n"
     ]
    }
   ],
   "source": [
    "# one hot encode train_labels\n",
    "train_labels = []\n",
    "for l in data0[1]:\n",
    "    one_hot = np.zeros(40, dtype=np.int)\n",
    "    one_hot[l[0]] = 1\n",
    "    train_labels.append(one_hot)\n",
    "train_labels = np.array(train_labels)\n",
    "print(np.shape(train_labels))\n",
    "# train_labels = train_labels.reshape((1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2468, 40)\n"
     ]
    }
   ],
   "source": [
    "# one hot encode test_labels\n",
    "test_labels_one_hot = []\n",
    "for l in test_labels:\n",
    "    one_hot = np.zeros(40, dtype=np.int)\n",
    "    one_hot[l[0]] = 1\n",
    "    test_labels_one_hot.append(one_hot)\n",
    "test_labels_one_hot = np.array(test_labels_one_hot)\n",
    "print(np.shape(test_labels_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 2048, 3, 1)\n",
      "(?, 2048, 1, 64)\n",
      "(?, 2048, 1, 64)\n",
      "(?, 2048, 1, 64)\n",
      "(?, 2048, 1, 128)\n",
      "(?, 2048, 1, 1024)\n",
      "(?, 1, 1, 1024)\n",
      "(?, 1, 1, 512)\n",
      "(?, 1, 1, 256)\n",
      "(?, 40)\n",
      "(?, 40)\n",
      "(?,)\n"
     ]
    }
   ],
   "source": [
    "cloud = tf.placeholder(tf.float32, [None, 2048, 3])\n",
    "pt_cloud = tf.expand_dims(cloud, -1)\n",
    "print(np.shape(pt_cloud))\n",
    "\n",
    "# placeholder for one-hot labels\n",
    "y = tf.placeholder(tf.float32, [None, 40])\n",
    "\n",
    "# placeholder for labels\n",
    "y_labels = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "# 1st mlp layer\n",
    "layer_conv1 = tf.contrib.layers.conv2d(inputs=pt_cloud, num_outputs=64, kernel_size=[1, 3], padding=\"VALID\", activation_fn=tf.nn.relu)\n",
    "print(np.shape(layer_conv1))\n",
    "\n",
    "# 2nd mlp layer\n",
    "layer_conv2 = tf.contrib.layers.conv2d(inputs=layer_conv1, num_outputs=64, kernel_size=[1, 1], activation_fn=tf.nn.relu)\n",
    "print(np.shape(layer_conv2))\n",
    "\n",
    "# 3rd mlp layer\n",
    "layer_conv3 = tf.contrib.layers.conv2d(inputs=layer_conv2, num_outputs=64, kernel_size=[1, 1], activation_fn=tf.nn.relu)\n",
    "print(np.shape(layer_conv3))\n",
    "\n",
    "# 4th cnn\n",
    "layer_conv4 = tf.contrib.layers.conv2d(inputs=layer_conv3, num_outputs=128, kernel_size=[1, 1], activation_fn=tf.nn.relu)\n",
    "print(np.shape(layer_conv4))\n",
    "\n",
    "# 5th cnn\n",
    "layer_conv5 = tf.contrib.layers.conv2d(inputs=layer_conv4, num_outputs=1024, kernel_size=[1, 1], activation_fn=tf.nn.relu)\n",
    "print(np.shape(layer_conv5))\n",
    "# max pooling\n",
    "max_pool = tf.contrib.layers.max_pool2d(inputs=layer_conv5, kernel_size=[2048, 1])\n",
    "\n",
    "print(np.shape(max_pool))\n",
    "\n",
    "# fnn1\n",
    "layer_fnn1 = tf.contrib.layers.fully_connected(inputs=max_pool, num_outputs=512, activation_fn=tf.nn.relu)\n",
    "print(np.shape(layer_fnn1))\n",
    "\n",
    "# fnn2\n",
    "layer_fnn2 = tf.contrib.layers.fully_connected(inputs=layer_fnn1, num_outputs=256, activation_fn=tf.nn.relu)\n",
    "print(np.shape(layer_fnn2))\n",
    "\n",
    "# fnn3\n",
    "logits = tf.contrib.layers.fully_connected(inputs=layer_fnn2, num_outputs=40, activation_fn=tf.nn.relu)\n",
    "logits = tf.squeeze(logits, [1, 2])\n",
    "print(np.shape(logits))\n",
    "\n",
    "# softmax\n",
    "output = tf.nn.softmax(logits)\n",
    "output_class = tf.argmax(output,axis=1)\n",
    "print(np.shape(output))\n",
    "print(np.shape(output_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = y))\n",
    "\n",
    "# optimizer\n",
    "optim = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6883676\n",
      "3.630666\n",
      "3.6752417\n",
      "3.4478877\n",
      "3.5090272\n",
      "3.1292477\n",
      "3.3995001\n",
      "2.842488\n",
      "3.1004167\n",
      "3.1292386\n",
      "3.1057978\n",
      "2.875028\n",
      "2.5700054\n",
      "3.0258102\n",
      "2.5077255\n",
      "2.6930163\n",
      "2.7006013\n",
      "2.946678\n",
      "2.5633278\n",
      "2.690843\n",
      "3.1583443\n",
      "2.6075232\n",
      "2.3408334\n",
      "2.7241614\n",
      "2.4397483\n",
      "2.8954577\n",
      "2.7254045\n",
      "2.2597213\n",
      "2.1729813\n",
      "3.0424538\n",
      "2.5747154\n",
      "2.242401\n",
      "2.8485646\n",
      "2.6325712\n",
      "2.8062203\n",
      "2.1256685\n",
      "2.3185055\n",
      "2.0054193\n",
      "1.9384116\n",
      "2.1578848\n",
      "2.0010295\n",
      "2.906476\n",
      "2.746409\n",
      "2.352211\n",
      "3.0249243\n",
      "3.0137627\n",
      "2.7252495\n",
      "2.7239833\n",
      "2.354665\n",
      "2.7254348\n",
      "2.413688\n",
      "2.3514051\n",
      "2.5844688\n",
      "1.8885489\n",
      "2.9672565\n",
      "2.7566178\n",
      "2.050758\n",
      "1.5851665\n",
      "2.6654687\n",
      "2.0931294\n",
      "2.588356\n",
      "1.9676259\n",
      "2.4125078\n",
      "2.165368\n",
      "2.137185\n",
      "1.879625\n",
      "2.1571715\n",
      "2.5405777\n",
      "1.8131428\n",
      "2.431563\n",
      "1.9472493\n",
      "2.172897\n",
      "2.9700828\n",
      "2.961849\n",
      "2.290831\n",
      "1.9131868\n",
      "2.2979844\n",
      "2.1478958\n",
      "1.7348738\n",
      "2.771872\n",
      "2.592445\n",
      "2.3853803\n",
      "2.723796\n",
      "1.9795232\n",
      "2.375208\n",
      "2.3821254\n",
      "2.6270514\n",
      "2.3427734\n",
      "2.915947\n",
      "1.5509845\n",
      "1.9872304\n",
      "1.7757483\n",
      "1.5927855\n",
      "1.973283\n",
      "2.46439\n",
      "2.228066\n",
      "2.1079655\n",
      "2.4159746\n",
      "2.539044\n",
      "2.007916\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "num_iter = 1000\n",
    "batch_size = 32\n",
    "\n",
    "for i in range(num_iter):\n",
    "    idx = np.random.choice(2048, [batch_size], False)\n",
    "    batch_img = train_data[idx][:]\n",
    "    batch_y = train_labels[idx][:]\n",
    "#     batch_img, batch_y = data.train.next_batch(batch_size)\n",
    "    _, l= sess.run([optim, loss], feed_dict = {cloud: batch_img , y: batch_y})\n",
    "    if i % 10 == 0:\n",
    "        print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n",
      "Accuracy [0.405]\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "correct_labels = tf.equal(output_class, y_labels)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_labels, tf.float32))\n",
    "# compute accuracy on test data\n",
    "labels = np.array([label.argmax() for label in test_labels_one_hot[:1000]])\n",
    "#print(np.shape(labels))\n",
    "accuracy = sess.run([accuracy],feed_dict = {cloud: test_data[:1000], y: test_labels_one_hot[:1000], y_labels: labels})\n",
    "print (\"Accuracy\" ,accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.shape(test_labels_one_hot[:10]))\n",
    "# labels = np.array([label.argmax() for label in test_labels_one_hot[:10]])\n",
    "# print(np.shape(labels))\n",
    "# print(np.shape(test_data[:10]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
