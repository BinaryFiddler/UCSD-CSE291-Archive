{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 Vanilla PointNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data and labels\n",
    "data0 = utils.load_h5(\"ply_data_train0.h5\")\n",
    "data1 = utils.load_h5(\"ply_data_train1.h5\")\n",
    "data2 = utils.load_h5(\"ply_data_train2.h5\")\n",
    "data3 = utils.load_h5(\"ply_data_train3.h5\")\n",
    "data4 = utils.load_h5(\"ply_data_train4.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9840, 2048, 3)\n",
      "(9840, 1)\n"
     ]
    }
   ],
   "source": [
    "# aggregate training data, training label\n",
    "train_data = np.append(data0[0], data1[0], axis=0)\n",
    "train_data = np.append(train_data, data2[0], axis=0)\n",
    "train_data = np.append(train_data, data3[0], axis=0)\n",
    "train_data = np.append(train_data, data4[0], axis=0)\n",
    "print(np.shape(train_data))\n",
    "\n",
    "train_labels = np.append(data0[1], data1[1], axis=0)\n",
    "train_labels = np.append(train_labels, data2[1], axis=0)\n",
    "train_labels = np.append(train_labels, data3[1], axis=0)\n",
    "train_labels = np.append(train_labels, data4[1], axis=0)\n",
    "print(np.shape(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test data\n",
    "test0 = utils.load_h5(\"ply_data_test0.h5\")\n",
    "test1 = utils.load_h5(\"ply_data_test1.h5\")\n",
    "# print(np.shape(test1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2468, 2048, 3)\n",
      "(2468, 1)\n"
     ]
    }
   ],
   "source": [
    "# aggregate test data, test label\n",
    "test_data = np.append(test0[0], test1[0], axis=0)\n",
    "test_labels = np.append(test0[1], test1[1], axis=0)\n",
    "print(np.shape(test_data))\n",
    "print(np.shape(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9840, 40)\n"
     ]
    }
   ],
   "source": [
    "train_labels_one_hot = []\n",
    "for l in train_labels:\n",
    "    one_hot = np.zeros(40, dtype=np.int)\n",
    "    one_hot[l[0]] = 1\n",
    "    train_labels_one_hot.append(one_hot)\n",
    "train_labels_one_hot = np.array(train_labels_one_hot)\n",
    "print(np.shape(train_labels_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2468, 40)\n"
     ]
    }
   ],
   "source": [
    "# one hot encode test_labels\n",
    "test_labels_one_hot = []\n",
    "for l in test_labels:\n",
    "    one_hot = np.zeros(40, dtype=np.int)\n",
    "    one_hot[l[0]] = 1\n",
    "    test_labels_one_hot.append(one_hot)\n",
    "test_labels_one_hot = np.array(test_labels_one_hot)\n",
    "print(np.shape(test_labels_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 2048, 3)\n"
     ]
    }
   ],
   "source": [
    "cloud = tf.placeholder(tf.float32, [None, 2048, 3])\n",
    "print(np.shape(cloud))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main network\n",
    "pt_cloud = tf.expand_dims(cloud, -1)\n",
    "\n",
    "# placeholder for one-hot labels\n",
    "y = tf.placeholder(tf.float32, [None, 40])\n",
    "\n",
    "# placeholder for labels\n",
    "y_labels = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "# 1st mlp layer\n",
    "layer_conv1 = tf.contrib.layers.conv2d(inputs=pt_cloud, num_outputs=64, kernel_size=[1, 3], padding=\"VALID\", activation_fn=tf.nn.relu)\n",
    "layer_conv1 = tf.contrib.layers.batch_norm(layer_conv1)\n",
    "\n",
    "# 2nd mlp layer\n",
    "layer_conv2 = tf.contrib.layers.conv2d(inputs=layer_conv1, num_outputs=64, kernel_size=[1, 1], padding=\"VALID\", activation_fn=tf.nn.relu)\n",
    "layer_conv2 = tf.contrib.layers.batch_norm(layer_conv2)\n",
    "\n",
    "\n",
    "# 3rd mlp layer\n",
    "layer_conv3 = tf.contrib.layers.conv2d(inputs=layer_conv2, num_outputs=64, kernel_size=[1, 1], padding=\"VALID\", activation_fn=tf.nn.relu)\n",
    "layer_conv3 = tf.contrib.layers.batch_norm(layer_conv3)\n",
    "\n",
    "\n",
    "# 4th cnn\n",
    "layer_conv4 = tf.contrib.layers.conv2d(inputs=layer_conv3, num_outputs=128, kernel_size=[1, 1], padding=\"VALID\", activation_fn=tf.nn.relu)\n",
    "layer_conv4 = tf.contrib.layers.batch_norm(layer_conv4)\n",
    "\n",
    "\n",
    "# 5th cnn\n",
    "layer_conv5 = tf.contrib.layers.conv2d(inputs=layer_conv4, num_outputs=1024, kernel_size=[1, 1], padding=\"VALID\", activation_fn=tf.nn.relu)\n",
    "layer_conv5 = tf.contrib.layers.batch_norm(layer_conv5)\n",
    "\n",
    "# max pooling\n",
    "max_pool = tf.contrib.layers.max_pool2d(inputs=layer_conv5, kernel_size=[2048, 1], stride=1, padding=\"VALID\")\n",
    "\n",
    "# fnn1\n",
    "layer_fnn1 = tf.contrib.layers.fully_connected(inputs=max_pool, num_outputs=512, activation_fn=tf.nn.relu)\n",
    "layer_fnn1 = tf.contrib.layers.batch_norm(layer_fnn1)\n",
    "\n",
    "# fnn2\n",
    "layer_fnn2 = tf.contrib.layers.fully_connected(inputs=layer_fnn1, num_outputs=256, activation_fn=tf.nn.relu)\n",
    "layer_fnn2 = tf.contrib.layers.batch_norm(layer_fnn2)\n",
    "\n",
    "layer_fnn2 = tf.contrib.layers.dropout(inputs=layer_fnn2, keep_prob=0.7)\n",
    "\n",
    "# fnn3\n",
    "logits = tf.contrib.layers.fully_connected(inputs=layer_fnn2, num_outputs=40, activation_fn=tf.nn.relu)\n",
    "logits = tf.squeeze(logits, [1, 2])\n",
    "\n",
    "# softmax\n",
    "output = tf.nn.softmax(logits)\n",
    "output_class = tf.argmax(output,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step = tf.Variable(0, trainable=False)\n",
    "starter_learning_rate = 0.001\n",
    "l_rate = tf.train.exponential_decay(starter_learning_rate, global_step, 20*batch_size, 0.5, staircase=True)\n",
    "\n",
    "# loss function\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logits, labels = y))\n",
    "\n",
    "# optimizer\n",
    "optim = tf.train.AdamOptimizer(learning_rate=l_rate)\n",
    "optimizer = optim.minimize(loss, global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "correct_labels = tf.equal(output_class, y_labels)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_labels, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import *\n",
    "import math\n",
    "# only rotate against y axis\n",
    "def rotate(pt_cloud):\n",
    "    angle = np.deg2rad(randint(0, 360))\n",
    "    R = np.array([[math.cos(angle), 0, math.sin(angle)], [0, 1, 0], [-math.sin(angle), 0, math.cos(angle)]])\n",
    "    rotated_pt_cloud = np.matmul(R, pt_cloud.T).T\n",
    "    return rotated_pt_cloud\n",
    "\n",
    "def jitter(pt_cloud):\n",
    "    return pt_cloud + np.random.normal(0, 0.02, None)\n",
    "\n",
    "def augment(pt_cloud):\n",
    "    seed = np.random.randint(10)\n",
    "    if seed == 0:\n",
    "        return rotate(jitter(pt_cloud))\n",
    "    elif seed == 1:\n",
    "        return rotate(pt_cloud)\n",
    "    elif seed == 2:\n",
    "        return jitter(pt_cloud)\n",
    "    else:\n",
    "        return pt_cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.33436 0.001\n",
      "1.34029 0.0005\n",
      "0.392139 0.00025\n",
      "0.28361 0.000125\n",
      "0.302493 6.25e-05\n",
      "0.204395 3.125e-05\n",
      "0.27048 1.5625e-05\n",
      "0.253359 7.8125e-06\n",
      "0.138807 3.90625e-06\n",
      "0.122358 1.95313e-06\n"
     ]
    }
   ],
   "source": [
    "train_data = np.array([augment(x) for x in train_data])\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "num_iter = int(200*batch_size)\n",
    "\n",
    "for i in range(num_iter):\n",
    "    idx = np.random.choice(9840, [batch_size], False)\n",
    "    batch_img_vanilla = train_data[idx][:]\n",
    "    batch_y = train_labels_one_hot[idx][:]\n",
    "    _, l, lr= sess.run([optimizer, loss, optim._lr], feed_dict = {cloud: batch_img_vanilla , y: batch_y})\n",
    "    if i % (batch_size*20) == 0:\n",
    "        print(l, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy 0.849270664506\n"
     ]
    }
   ],
   "source": [
    "right_count = 0\n",
    "i = 0\n",
    "while i < len(test_data):\n",
    "    j = min(i + 32, len(test_data))\n",
    "    correct_labels = tf.equal(output_class, y_labels)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_labels, tf.float32))\n",
    "    # compute accuracy on test data\n",
    "    labels = np.array([label.argmax() for label in test_labels_one_hot[i:j]])\n",
    "    accuracy = sess.run([accuracy],feed_dict = {cloud: test_data[i:j], y: test_labels_one_hot[i:j], y_labels: labels})\n",
    "    right_count = right_count + accuracy[0] * (j - i)\n",
    "    i += 32\n",
    "final_accuracy = right_count / len(test_data)\n",
    "print(\"Final Accuracy\", final_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
